{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31f3f150-ce51-48eb-a321-fe0b94888fbf",
   "metadata": {},
   "source": [
    "## Adopt BLIP2 and LLM to solve content moderation\n",
    "\n",
    "This notebook demonstrate how we can adopt BLIP2 and LLM for content moderation. To align with the tradicitonal approach as [Moderating content](https://docs.aws.amazon.com/rekognition/latest/dg/moderation.html), we also categorize contents into different categories. For each category, like check-list we define questions to check if the content belongs to that category. For few questions, we may just check if all answers meet the defined answers, but for many questions with different type answers, designing rule-based process may be complicated, therefore we leverage LLM to summarize the result based on the questions and answers from BLIP2 model. The architecture is below:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/architecture.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1898f08a-58d3-401f-9a80-3e949c3191c7",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a96aae6-f194-477f-b598-3ba4731c0dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "endpoint_name = \"blip22023-07-23-15-40-56\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671d99d-bbef-4ad7-9b2f-3db68b6bfa06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image(img_file):\n",
    "    with open(img_file, \"rb\") as image_file:\n",
    "        img_str = base64.b64encode(image_file.read())\n",
    "        base64_string = img_str.decode(\"latin1\")\n",
    "    return base64_string\n",
    "\n",
    "def run_inference(endpoint_name, inputs):\n",
    "    response = smr_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    "    )\n",
    "    return response[\"Body\"].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4219377-100b-48fc-806c-75d0bf3adcf1",
   "metadata": {},
   "source": [
    "## Run BLIP2 to extract text information from image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b24df9-dcf3-412b-9266-eb039c22dabb",
   "metadata": {},
   "source": [
    "### Define questions\n",
    "We define a list of questions without category setting, and put all QA results into prompt for LLM, ask LLM to categorize if the content is unsafe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8e83a-7a6f-44c4-b408-bf37d458962d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_list_v1 = [\n",
    "    \"Does this photo contain naked person?\",\n",
    "    \"Does this photo contain topless person?\",\n",
    "    \"Does this photo contain topless man and topless woman?\",\n",
    "    \"Does this photo contain weapon?\",\n",
    "    \"Does this photo contain contact information?\",\n",
    "    \"Does this photo contain a smoker?\",\n",
    "    \"Does this photo contain blood?\",\n",
    "    \"Are there persons fighting in this photo?\",\n",
    "    \"Does this photo contain harassment words?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7dd515-6fba-4817-90b3-983599104f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://static.us-east-1.prod.workshops.aws/public/6e73f8b0-9e22-4a5a-a2fc-7d99d5605161/static/images/moduleimg/01-01-dataset.jpg -O datasets/yoga_swimwear_lighttext.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fe38d-8bd7-4f5b-b1a1-466035ba1051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_image = \"./datasets/yoga_swimwear_lighttext.jpg\"\n",
    "raw_image = Image.open(test_image).convert('RGB')\n",
    "display(raw_image.resize((596, 437)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b62d4-51c2-4144-889d-d884cdc31142",
   "metadata": {},
   "source": [
    "### run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55979e-2ad7-4b34-a13d-ac8ea6d85241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base64_string = encode_image(test_image)\n",
    "\n",
    "inputs = {\"prompt\": \"Question: describe the content in 200 words. Answer:\", \"image\": base64_string}\n",
    "response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    ")\n",
    "image_caption = response[\"Body\"].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c76cbe4-150d-4c50-a8a7-b38cf2e922bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_check_list(test_image, check_list):\n",
    "    base64_string = encode_image(test_image)\n",
    "    conversations = \"\"\"\"\"\"\n",
    "    for question in check_list:\n",
    "        inputs = {\"prompt\": f\"Question: {question}? Answer:\", \"image\": base64_string}\n",
    "        response = run_inference(endpoint_name, inputs)\n",
    "        conversations += f\"\"\"\n",
    "Question: {question}\n",
    "Answer: {response}.\n",
    "\"\"\"\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e0d68-e8b1-4a34-8d35-17e6da97530c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversations = run_check_list(test_image, check_list_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc496beb-0ce6-4a51-aa7d-f7402c69ffd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d0ed7-d54d-4f7b-8a4d-19a4a9cb8a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversations += f\"\"\"\n",
    "Question: What does this photo contain?\n",
    "Answer: {image_caption}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6336804-b711-45db-9b42-d46dee10398a",
   "metadata": {},
   "source": [
    "## Summarize questions and answers with LLM\n",
    "\n",
    "Before running this section, make sure you have already deployed a LLM model, here we deploy LLAMA 2 released by META, you can deploy LLAMA 2 from SageMaker JumpStart.\n",
    "\n",
    "### Define policy\n",
    "We prepare moderation policy by referring to [Moderating content](https://docs.aws.amazon.com/rekognition/latest/dg/moderation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8075d4a-b60e-40c8-afb8-dec42e44458c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moderation_policy = \"\"\"\n",
    "1. Explicit Nudity: it contains Nudity, Graphic Male Nudity, Graphic Female Nudity, Sexual Activity, Illustrated Explicit Nudity and Adult Toys.\n",
    "2. Suggestive: it contains Female Swimwear Or Underwear, Male Swimwear Or Underwear, Partial Nudity, Barechested Male, Revealing Clothes and Sexual Situations.\n",
    "3. Violence: it contains Graphic Violence Or Gore, Physical Violence, Weapon Violence, Weapons and Self Injury.\n",
    "4. Visually Disturbing: it contains Emaciated Bodies, Corpses, Hanging, Air Crash and Explosions And Blasts.\n",
    "5. Rude Gestures: it contains Middle Finger.\n",
    "6. Drugs: it contains Drug Products, Drug Use, Pills and Drug Paraphernalia.\n",
    "7. Tobacco: it contains contain Tobacco Products and Smoking.\n",
    "8. Alcohol: it contains Drinking and Alcoholic Beverages.\n",
    "9. Gambling: it contains Gambling.\n",
    "10. Hate Symbols: it contains Nazi Party, White Supremacy and Extremist.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e2f41-ec1c-451d-9855-53da8ed7640f",
   "metadata": {},
   "source": [
    "### Define prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be236aa-cb9c-4fc0-89f7-b7553f71016b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = f\"\"\"\n",
    "The following is our company's content moderation policy, based on the moderation policy, we gather image information from the user uploaded image. Please answer the question with json format. \n",
    "        \n",
    "###### moderation policy ######\n",
    "{moderation_policy}\n",
    "        \n",
    "###### Image information ######\n",
    "{conversations}\n",
    "        \n",
    "###### Question ######\n",
    "Based on the following Moderation policy and QA, tell me if the photo containes unsafe content, also give its category and reason if it's unsafe. Please anwser the question with the following format and only put explanation into the reason field:  \n",
    "\"\"\"\n",
    "\n",
    "prompt_template += \"\"\"\n",
    "{\n",
    "    \"flag\": \"xxx\",\n",
    "    \"category\": \"xxx\",\n",
    "    \"reason\": \"the reason is ...\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623e23b-983d-4836-b1c3-81b78629c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = [\n",
    "    {\"role\": \"user\", \"content\": prompt_template}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232337db-51b7-47a0-8841-8a2954f08c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"jumpstart-dft-meta-textgeneration-llama-2-70b-f\"\n",
    "\n",
    "def query_endpoint(payload):\n",
    "    client = boto3.client(\"sagemaker-runtime\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps(payload),\n",
    "        CustomAttributes=\"accept_eula=true\",\n",
    "    )\n",
    "    response = response[\"Body\"].read().decode(\"utf8\")\n",
    "    response = json.loads(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b742e58d-01ed-4de6-8506-4914bf45f416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"inputs\": [dialog], \n",
    "    \"parameters\": {\"max_new_tokens\": 256, \"top_p\": 0.9, \"temperature\": 0.5}\n",
    "}\n",
    "result = query_endpoint(payload)[0]\n",
    "for msg in dialog:\n",
    "    print(f\"{msg['role'].capitalize()}: {msg['content']}\\n\")\n",
    "print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d6930-ce65-4a21-949c-9db55505fc3a",
   "metadata": {},
   "source": [
    "### Process result as dictionary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fecc133-f300-494d-b5cb-00b5e8de93dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer = result['generation']['content'].split('}')[0]+'}'\n",
    "json.loads(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b52ad-c013-4d3e-bfb7-9fcc63c225cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
